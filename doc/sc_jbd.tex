%% BioMed_Central_Tex_Template_v1.06
%%                                      %
%  bmc_article.tex            ver: 1.06 %
%                                       %

%%IMPORTANT: do not delete the first line of this template
%%It must be present to enable the BMC Submission system to
%%recognise this template!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%          <8 June 2012>              %%
%%                                     %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.html and the instructions for   %%
%% authors page on the biomed central website                      %%
%% https://www.biomedcentral.com/getpublished                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% https://miktex.org/                                             %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% additional documentclass options:
%  [doublespacing]
%  [linenumbers]   - put the line numbers on margins

%%% loading packages, author definitions

%\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
\documentclass{bmcart}

%%% Load packages
\usepackage{amsthm,amsmath}
\usepackage{tabularx}
\usepackage{xspace}
\usepackage{color}
\usepackage{epsfig}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}

\usepackage{tikz}
%\usepackage{fullpage}
\usepackage{calc}
\usetikzlibrary{positioning,shadows,arrows,trees,shapes,fit}
\usepackage{blindtext}
\usepackage{pgfplots}
%\pgfplotsset{compat=1.16}
\usepackage{pythonhighlight}
\usepackage{fixme}
\fxsetup{status=draft} % <====== add this line
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algpseudocode}
  
\usepackage{url}
\raggedbottom
%\algnewcommand\algorithmicforeach{\textbf{for each}}
%\algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}

% scaling factor for tables
\newcommand\tabscale{0.8}
\newtheorem{definition}{Definition}
\newtheorem{Lemma}{Lemma}


\usepackage{fixme}

  
%\RequirePackage[numbers]{natbib}
%\RequirePackage[authoryear]{natbib}% uncomment this for author-year bibliography
%\RequirePackage{hyperref}
\usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails
%\usepackage[latin1]{inputenc} %UNIX support if unicode package fails

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %%
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %%
%%  submitted article.                         %%
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\def\includegraphic{}
%\def\includegraphics{}

%%% Put your definitions there:
\startlocaldefs
\endlocaldefs

%%% Begin ...
\begin{document}

%%% Start of article front matter
\begin{frontmatter}

\begin{fmbox}
\dochead{Research}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Symbolic classification with RILS-ROLS and HROCH algorithms}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Specify information, if available,       %%
%% in the form:                             %%
%%   <key>={<id1>,<id2>}                    %%
%%   <key>=                                 %%
%% Comment or delete the keys which are     %%
%% not used. Repeat \author command as much %%
%% as required.                             %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author[
  addressref={aff1},                   % id's of addresses, e.g. {aff1,aff2}
  corref={aff1},                       % id of corresponding address, if any
% noteref={n1},                        % id's of article notes, if any
  email={kartelj@matf.bg.ac.rs}   % email address
]{\inits{A.K.}\fnm{Aleksandar} \snm{Kartelj}}
\author[
  addressref={aff2},
  email={marko.djukanovic@pmf.unibl.org}
]{\inits{M.DJ.}\fnm{Marko} \snm{DjukanoviÄ‡}}

\author[
email={jan.pigos@gmail.com}
]{\inits{M.DJ.}\fnm{Jan} \snm{Pingos}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors' addresses here        %%
%%                                          %%
%% Repeat \address commands as much as      %%
%% required.                                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\address[id=aff1]{%                           % unique id
  \orgdiv{Department of Informatics, Faculty of Mathematics},             % department, if any
  \orgname{University of Belgrade},          % university, etc
  \city{Belgrade},                              % city
  \cny{Serbia}                                    % country
}
\address[id=aff2]{%
  \orgdiv{Faculty of Sciences and Mathematics},
  \orgname{University of Banja Luka},
  %\street{},
  %\postcode{}
  \city{Banja Luka},
  \cny{Bosnia and Herzegovina}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter short notes here                   %%
%%                                          %%
%% Short notes will be after addresses      %%
%% on first page.                           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{artnotes}
%%\note{Sample of title note}     % note to the article
%\note[id=n1]{Equal contributor} % note, connected to author
%\end{artnotes}

\end{fmbox}% comment this for two column layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                           %%
%% The Abstract begins here                  %%
%%                                           %%
%% Please refer to the Instructions for      %%
%% authors on https://www.biomedcentral.com/ %%
%% and include the section headings          %%
%% accordingly for your article type.        %%
%%                                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstractbox}

\begin{abstract} % abstract
In this paper, we solve the symbolic classification problem. TODO
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The keywords begin here                  %%
%%                                          %%
%% Put each keyword in separate \kwd{}.     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{keyword}
\kwd{symbolic classification}
\kwd{iterated local search}
\kwd{ordinary least squares}
\kwd{hill climbing}
\end{keyword}

% MSC classifications codes, if any
%\begin{keyword}[class=AMS]
%\kwd[Primary ]{}
%\kwd{}
%\kwd[; secondary ]{}
%\end{keyword}

\end{abstractbox}
%
%\end{fmbox}% uncomment this for two column layout

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                            %%
%% The Main Body begins here                  %%
%%                                            %%
%% Please refer to the instructions for       %%
%% authors on:                                %%
%% https://www.biomedcentral.com/getpublished %%
%% and include the section headings           %%
%% accordingly for your article type.         %%
%%                                            %%
%% See the Results and Discussion section     %%
%% for details on how to create sub-sections  %%
%%                                            %%
%% use \cite{...} to cite references          %%
%%  \cite{koon} and                           %%
%%  \cite{oreg,khar,zvai,xjon,schn,pond}      %%
%%                                            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% start of article main body
% <put your article body there>

%%%%%%%%%%%%%%%%
%% Background %%
%%
	\section{Introduction}\label{sec:introduction}

The problem of symbolic regression (SR)~\cite{billard2002symbolic} is one of a central problem in the filed of machine learning (ML) and mathematical optimization; it has attracted many researchers to study it over the last few decades. 
SR can be seen as  a type of regression analysis; it  searches a mathematical expressions $f$, called a model,  that best fits to the data; more precisely,  given is a set of input data $\textbf{X}$ and a set of target variables $\textbf{y}$, we aim at a mathematical formula $f$ that explains the target variable in terms of the input data, that is $f(\textbf{X}) = \textbf{y}$. In essence, a good candidate solution $f$ must be accurate enough to the output variables as well simple enough. The problem itself can be seen as a generalization of specific variants of regression where the desired functional form of model $f$ is pre-assumed, e.g., the well-known linear regression considers only linear-form models, while polynomial regression allows any polynomial for a feasible model~\cite{stimson1978interpreting}, etc. SR problem can be seen as an of-shot of the Genetic programming (GP) methodology introduced by Koza~\cite{koza1994genetic}.  SR has received many attention being solved by a few dozens of algorithms such as Genetic programming~\cite{augusto2000symbolic}, a Bee colony optimization algorithm~\cite{karaboga2012artificial}, a divide-and-conquer based approaches~\cite{udrescu2020ai}, an iterated greedy--based method RILS-ROLS~\cite{kartelj2023rils}, just to name a few.  The later approach is proven to be  the current state-of-the-art on the ground-truth SR problems from literature, that are collected in the two well-known benchmark sets, labelled Feynman and Strogatz. It is worth mentioning that when comes to solving  black-box SR, that is, when the task is to seek a best fitting model on data quantified by, e.g.,  $R^2$ value (or some other measure of success) without knowing what the real model is, the best performing algorithms from literature are  Operon~\cite{burlacu2020operon}, SBP-GP~\cite{virgolin2019linear}, followed by the above-mentioned RILS-ROLS. By popularization of SR among the researchers, uniform, robust, and transparent
benchmarking standards were not known until the work of  La Cava et al.~\cite{la2021contemporary}, who  introduced an open-source, reproducible benchmarking platform \texttt{SRBench}. The authors extended  PMLB~\cite{olson2017pmlb} with a newly 130 SR datasets for which exact models are known. \texttt{SRBench} can execute 14 SR methods and 7 ML methods on the set of 252  regression problems. The rest (122) SR datasets belong to the class of  \emph{black-box} problems (the ground-truth is unknown).

Nowadays, SR is pushed into the rank of moderate-to-extreme accuracy.  It has proven its strength and applicability in solving many problems from various research fields such as material science~\cite{wang2019symbolic}, wind speed forecasting~\cite{abdellaoui2021symbolic},  highway crash prediction~\cite{veran2023interpretable}, language assessment~\cite{aryadoust2015application}, etc.  Solving SR is known to be NP-hard in general~\cite{virgolin2022symbolic}. 


Classification belongs to the field of supervised learning and many algorithms have been proposed to tackle various classes of classification problems (binary, multinomial, multi-class, etc.), see, for example~\cite{cunningham2008supervised, caruana2006empirical}. When comes to the \emph{symbolic classification} (SC) problem, the task here is to finding suitable models (classifiers)  $f^i$ for each class $i \in C$ of a (discrete, finite) set of classes $C$ which are further projected into a dominant  class, by, for example, \texttt{sotfmax}, or \texttt{argmax} transformations (known by the name \emph{one-vs-rest} or \emph{one-to-all}  method). A considerably less work have been done for SC in contrast to SR. Note that solving SR efficiently is just a half of a way to achieve it also for SC. It is known that directly applying GP is not in particular successful for solving the multi-class classification problems especially when comes to the problems with a high number of classes~\cite{korns2018evolutionary}. A survey paper on applying GP to solve (binary and multi-class) classification problems is provided in~\cite{espejo2009survey}.  In the last decade, several papers have been published which succeed to raised the SC accuracy in the level to complete with the existing commercial classification tools. These tools are based on evolutionary algorithms~\cite{korns2018evolutionary}, a Multidimensional genetic programming based approach~\cite{munoz2015m3gp,la2019multidimensional},  evolutionary discriminant analysis~\cite{korns2017evolutionary}, etc. 

In this paper, motivated by the success of solving SR efficiently provided by the recent studies, we propose two new classification algorithms that solve the problem of SC: ($i$) RILS-ROLS classifier, and ($ii$) HROCH classifier. 


\fxnote{TODO: say something more about these methods!}

%All regression models have the same goal: given a set of $n$-dimensional input data and its corresponding continuous output target variable, the aim is to find a  mathematical expression (function) of $n$ (input) variables that best \emph{fits} the target variable.  %This computationally intensive task is in general provenly NP--hard~\cite{virgolin2022symbolic}. 
%In the case of linear regression, the model is always a linear combination of input variables. This is in general not good enough, since the target variable might be dependent on a nonlinear function among input variables. Unlike linear regression, SR allows for the search over much larger space of possible mathematical formulas to find the best-fitting ones, i.e., those able to predict the target variable from input variables. The basis of constructing an explicit formula is in elementary operations like addition and multiplication, as well as polynomial, trigonometric, exponential, and other operations.  
%Application: https://towardsdatascience.com/real-world-applications-of-symbolic-regression-2025d17b88ef
 
 

\subsection{Contributions}\label{sec:contibutions}

The main contributions are as follows: 

\begin{enumerate}
	\item We contributed to the field of Symbolic classification by providing two more classification algorithms at disposal. 
	
	\item The proposed methods are evaluated against state-of-the-art classification algorithms as well as a few state-of-the-art SC algorithms from literature. 
	\item \fxnote{TODO}
\end{enumerate}
 
\section{Definitions and notation} \label{sec:search-space}

In this section we formally define the SR problem.

\begin{definition}\label{dfn:sr}
	Given is a dataset $D = \{(\mathbf{x_i}, y_i)\}_{i=1}^n$, where $\mathbf{x_i} \in \mathbb{R}^d$ represents the $i$-th feature (input) vector and $y_i \in \mathbb{R}$ is its corresponding target (output) variable. Suppose the existence of an analytical model of the form $s(\mathbf{x})= g^*(\mathbf{x}, \theta^*) + \epsilon $ that can generate  all observations from $D$.  
	SR aims at learning $\tilde{s}(\mathbf{x})=  \tilde{g}(\mathbf{x}, \tilde{\theta})  \colon \mathbb{R}^d \mapsto \mathbb{R}$  estimated by searching through the space of (mathematical) expressions  $\tilde{g}$ and parameters $\tilde{\theta}$ where  $\epsilon$ is the observed white noise within the given input data. 
	
\end{definition}


\begin{definition}\label{dfn:sc}
	Given is a dataset $D = \{(\mathbf{x_i}, c_i)\}_{i=1}^n$, where $\mathbf{x_i}$ represents the $i$-th feature vector, and $c_i$  dependent unordered categorical
	 value from e.g., $\{1, \ldots, K  \} $, $K\geq 2. $ The aim of SC is to find $K$ (mathematical) expressions $s^i, i=1, \ldots, K$, so that $s(\mathbf{x_i}) = T( s^1\mathbf{x_i}), \ldots, s^K(\mathbf{x_i})  ) = c_i,$ for $i=1, \ldots, K$ where the classification is performed with $T$ which can be based on a threshold  or some other transformation technique, e.g., applying \textrm{argmax}. 
  \end{definition}
 
 
\emph{Notation}. Let $s \colon \mathbb{R}^d \mapsto \mathbb{R}$ be a model for data $D$ from Definition~\ref{dfn:sr}.  We introduce the following notation for SR. 
 
\begin{equation}
		R^2(s) = 1- \frac{ \sum_{i=1}^{n} \left( s(\mathbf{x_i}) - y_i \right)^2  }{ \sum_{i=1}^{n} \left( y_{i}  - \overline{y} \right)^2  }
	\end{equation}
	\begin{equation}
		RMSE(s) = \sqrt {\frac{1}{n} \sum_{i=1}^{n} (s(\mathbf{x_i}) - y_{i})^2}
	\end{equation}
	
 Here, $s(\mathbf{x_i})$ for the value predicted by the candidate model $s$ for an input vector $\mathbf{x_i}$, $y_{i}$ for the (exact) target value, and $\overline{y}$ for the mean of all target values.
 
Concerning notation regarding SC, we mention the following metrics %https://www.evidentlyai.com/classification-metrics/multi-class-metrics
\begin{itemize}
    \item \emph{accuracy} metric: a measure how many observations were correctly classified;
    \item   \emph{precision} metric: one calculate the precision for each class individually, and then to ``average'' the precision  across all classes (use macro or micro averaging).
    \item  \emph{recall} metric: the same calculation as for the precision metric performed but with the \emph{recall}; recall verifies the model's ability of identifying all instances of a particular class. 
    \item $F_1$ metric: the harmonic mean of two score, precision and recall; in the multi-class classification, the $F_1$ score is calculated per class applying one-vs-rest manner. 
     %https://www.baeldung.com/cs/multi-class-f1-score
       
\end{itemize}
 
%In this section we formally define the SR problem.

%\begin{definition}
%	Given is a dataset $D = \{(\mathbf{x_i}, y_i)\}_{i=1}^n$, where $\mathbf{x_i} \in \mathbb{R}^d$ represents the i-th feature (input) vector while $y_i \in \mathbb{R}$ is its corresponding target (output) variable. Suppose that there exists an analytical model of the form $f(\mathbf{x})= g^*(\mathbf{x}, \theta^*) + \epsilon $ that is a generator of all observations from $D$.  
%	The goal of SR is to learn the mapping $\tilde{f}(\mathbf{x})=  \tilde{g}(\mathbf{x}, \tilde{\theta})  \colon \mathbb{R}^d \mapsto \mathbb{R}$  estimated by searching through the space of (mathematical) expressions  $\tilde{g}$ and parameters $\tilde{\theta}$ where  $\epsilon$ is the observed white noise within the given input data. 
	
%\end{definition}

%Koza~\cite{koza1994genetic} introduced the problem of SR as a specific application of genetic programming. GP can be used to optimize nonlinear structures such as computer programs. In particular, programs are represented by syntax trees consisting of functions/operations over input features and constants. As an example of a function represented by a syntax tree, see Figure~\ref{fig:syntax-tree-example}. In essence, all valid syntax trees form the solution search space of SR. That is, each sample model $\tilde{f}$ may be seen as a point in the search space, represented by a respective syntax tree. The solution accuracy can be computed on the basis of historical data $D$ and the chosen error measure such as $MSE$, $RMSE$, $R^2$, their combination, etc. Interestingly, the nature of SR search space is twofold: discrete and continuous. It is primarily modeled as a problem of discrete (combinatorial) optimization, since the number of possible solution functional forms is countable. However, it may also include elements solved by means of continuous (global) optimization, e.g., constants (coefficients) fitting. It is common to use the set of the following elementary mathematical functions: $\sqrt{x}, x^2 $, $\sin$, $\cos$, $\log$, $\exp$, $\arcsin$, $\arccos$, $a^x$, and a set of standard arithmetic operators: $+$, $-$, $\cdot$, and $/$. 
 

	\section{The proposed algorithms}\label{sec:rils}

 This section presents two new classification algorithms for the problem of Symbolic classification. The first one are based on the state-of-the-art method to solving ground-truth-based SR, whilst the second one is a new \textsc{Hroch} method that is based on a classical hill-climbing methodology utilizing a high degree of parallelism in there. 
 

\subsection{The \textsc{RILS}-\textsc{ROLS}  classifier}

Let us first describe the basic principle on which the \textsc{Rils}-\textsc{Rols} algorithms is built on. For all the details on this method, we refer readers to the paper~\cite{kartelj2023rils}. 

 This method combines the popular iterated local search meta-heuristic (ILS)~\cite{lourencco2003iterated,lourencco2010iterated} with the ordinary least square method (OLS)~\cite{leng2007ordinary}.  Iterated local search serves as a method backbone, which mainly tackles combinatorial aspects of the problem consisting of searching for essential functional forms which are further tuned later in the search to generate good solutions. OLS algorithm tackles continuous aspects of the problem, that is it efficiently determines best-fitting coefficients of  linear  combinations within solution equations. One of the  important steps of the algorithm is generating perturbations near a solution, i.e. the set of solutions  which are close to solution $s$ with a ``distance'' of 1 (called 1-perturbation). This is done by making simple changes on the per-node level of solution's expression tree.  These per-node change operations are predefined in the algorithm, see~\cite{kartelj2023rils}.  
 
 To verify goodness of solutions in the search process, a carefully designed fitness function has been utilized which takes into consideration three model quality scores -- $R^2$, \emph{RMSE} and the size of model, combined in a non-linear function. In order to intensify the search, an efficient local search procedure has been employed around each solution, based on the concept of the extended 1--perturbations, so generating solutions which are in the vicinity of solution $s$ respecting the extended set of pre-defined per-node-changes. LS applies the best-improvement search strategy,  see the above-mentioned paper. It is worth noting that the LS plays an important role as it also performs general coefficient tuning, unlike OLS that does the fitting only in linear combinations.  
 
 
 \fxnote{TODO. explain the process of transformation of RILS-ROLS  to a classifier...}
 
 \subsection{The \textsc{Hroch}  classifier}
 \fxnote{TODO}
 XX
 
\section{Experimental evaluation}\label{sec:experiments}

Our  algorithm is implemented in XX. All experiments concerning our method are conducted in the single-core mode, on a PC with Intel i9-9900KF CPU @3.6GHz, 64GB RAM, under Windows 10 Pro OS. The RAM consumption was very small (up to a few hundred megabytes).   

The following algorithms  are compared: XX...


\subsection{Datasets}
 XX
 
\section{Conclusions and future work}\label{sec:conclusions}
XX
 \fxnote{TODO}
\begin{backmatter}

 \section*{Acknowledgments}%% if any
Not applicable.

 \section*{Funding}%% if any
Not applicable.

%\section*{Abbreviations}%% if any
%Text for this section\ldots

  \section*{Availability of data and materials}%% if any
 All accompanying resources regarding this paper can be found in the GitHub repository \url{https://github.com/XX/XX}. 

\section*{Ethics approval and consent to participate}%% if any
Not applicable. 

\section*{Competing interests}
The authors declare  no competing interests.

\section*{Consent for publication}%% if any
Not applicable. 

\section*{Authors' contributions}
Both A.K. and M.Dj. contributed to the conception of the work. A.K. worked on the implementation of method and the design of experiments. M.Dj. worked on analysis and discussion of the results, introduction and literature review. 

%\section*{Authors' information}%% if any
%Text for this section\ldots

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  Bmc_mathpys.bst  will be used to                       %%
%%  create a .BBL file for submission.                     %%
%%  After submission of the .TEX file,                     %%
%%  you will be prompted to submit your .BBL file.         %%
%%                                                         %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% if your bibliography is in bibtex format, use those commands:
\bibliographystyle{bmc-mathphys} % Style BST file (bmc-mathphys, vancouver, spbasic).
\bibliography{bib}      % Bibliography file (usually '*.bib' )
 
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Figures                       %%
%%                               %%
%% NB: this is for captions and  %%
%% Titles. All graphics must be  %%
%% submitted separately and NOT  %%
%% included in the Tex document  %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Do not use \listoffigures as most will included as separate files
 

 
 

%\section*{Additional Files}
%  \subsection*{Additional file 1 --- Sample additional file title}
 %   Additional file descriptions text (including details of how to
 %   view the file, if it is in a non-standard format or the file extension).  This might
 %   refer to a multi-page table or a figure...
 

\end{backmatter}
\end{document}
